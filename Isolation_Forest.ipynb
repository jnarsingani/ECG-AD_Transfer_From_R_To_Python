{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68dccc34",
   "metadata": {},
   "source": [
    "# Step 4: Isolation Forest Variants\n",
    "\n",
    "**Learning Objectives:**\n",
    "1. Understand how Isolation Forest works (unsupervised anomaly detection)\n",
    "2. Implement Standard Isolation Forest\n",
    "3. Compare with Random Forest results\n",
    "4. Understand contamination parameter\n",
    "5. Analyze sensitivity vs specificity tradeoffs\n",
    "\n",
    "---\n",
    "\n",
    "## What is Isolation Forest?\n",
    "\n",
    "**Key Concept:** Anomalies are \"easier to isolate\" than normal points.\n",
    "\n",
    "**How it works:**\n",
    "- Build random decision trees\n",
    "- Anomalies get isolated with fewer splits\n",
    "- Gives each point an \"anomaly score\"\n",
    "- Higher score = more likely to be anomaly\n",
    "\n",
    "**Key Parameter:**\n",
    "- `contamination`: Expected proportion of anomalies (we use 0.101 = 10.1%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277c7432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data and the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pickle\n",
    "from sklearn.ensemble import IsolationForest \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "import time \n",
    "\n",
    "# Seed\n",
    "random_seed = 123\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load preprocessed data\n",
    "with open('preprocessed_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Extract the needed data \n",
    "X_train_scaled = data['X_train_scaled']  # Isolation Forest needs scaled data!\n",
    "X_test_scaled = data['X_test_scaled']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "contamination_rate = data['contamination_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1db7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   2 out of  16 | elapsed:    0.0s remaining:    0.9s\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model completed in 0.39 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Train Standard Isolation Forest\n",
    "\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators = 100,            # Number of trees\n",
    "    max_samples = 1000,            # Sample size per tree\n",
    "    contamination = contamination_rate, # Expected proportion of anomalies\n",
    "    random_state = random_seed,\n",
    "    n_jobs = -1,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# Train the model \n",
    "start_time = time.time()\n",
    "\n",
    "iso_forest.fit(X_train_scaled)\n",
    "\n",
    "training_time = time.time()-start_time\n",
    "print(f\"Training model completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9b8737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Predictions:\n",
      "  Normal (0):   39,691\n",
      "  Abnormal (1): 4,703\n",
      "\n",
      "Expected abnormal (based on contamination): 4,733\n",
      "Actual predicted abnormal: 4,703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Making prediction \n",
    "\n",
    "# Predict on test set\n",
    "# Returns -1 for anomalies, 1 for normal - Sklearn convention \n",
    "y_pred_if_raw = iso_forest.predict(X_test_scaled)\n",
    "\n",
    "# Convert to our format: 0 = Normal, 1 = Anomaly \n",
    "# sklearn: 1=normal, -1=anomaly\n",
    "# We need: 0=normal, 1=anomaly\n",
    "y_pred_if = np.where(y_pred_if_raw == -1, 1, 0)\n",
    "\n",
    "# Counting prediction \n",
    "unique, counts = np.unique(y_pred_if, return_counts = True)\n",
    "pred_dict = dict(zip(unique, counts))\n",
    "\n",
    "print(f\"\\n Predictions:\")\n",
    "print(f\"  Normal (0):   {pred_dict.get(0, 0):,}\")\n",
    "print(f\"  Abnormal (1): {pred_dict.get(1, 0):,}\")\n",
    "\n",
    "# Expected abnormal based on contamination\n",
    "expected_abnormal = int(len(y_test) * contamination_rate)\n",
    "print(f\"\\nExpected abnormal (based on contamination): {expected_abnormal:,}\")\n",
    "print(f\"Actual predicted abnormal: {pred_dict.get(1, 0):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ba6cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Normal     36689    2972\n",
      "       Abnormal    3002    1731\n",
      "\n",
      "======================================================================\n",
      "METRICS:\n",
      "======================================================================\n",
      "Accuracy:    86.54%\n",
      "Sensitivity: 36.57%  (catches 36.6% of abnormal)\n",
      "Specificity: 92.51%  (catches 92.5% of normal)\n",
      "\n",
      "======================================================================\n",
      "COMPARISON:\n",
      "======================================================================\n",
      "Random Forest:      Acc=98.14%, Sens=84.62%, Spec=99.75%\n",
      "Isolation Forest:   Acc=86.54%, Sens=36.57%, Spec=92.51%\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance matricies \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Calculate metrics \n",
    "accuracy = accuracy_score(y_test, y_pred_if)\n",
    "\n",
    "# Confusion matrix \n",
    "conf_matrix = confusion_matrix(y_test, y_pred_if)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Calculate sensitivity and specificity \n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Actual Normal    {tn:6d}  {fp:6d}\")\n",
    "print(f\"       Abnormal  {fn:6d}  {tp:6d}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"METRICS:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy:    {accuracy*100:.2f}%\")\n",
    "print(f\"Sensitivity: {sensitivity*100:.2f}%  (catches {sensitivity*100:.1f}% of abnormal)\")\n",
    "print(f\"Specificity: {specificity*100:.2f}%  (catches {specificity*100:.1f}% of normal)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"COMPARISON:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Random Forest:      Acc={98.14:.2f}%, Sens={84.62:.2f}%, Spec={99.75:.2f}%\")\n",
    "print(f\"Isolation Forest:   Acc={accuracy*100:.2f}%, Sens={sensitivity*100:.2f}%, Spec={specificity*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c35ac26",
   "metadata": {},
   "source": [
    "\n",
    "## Single-Variable Isolation Forest\n",
    "\n",
    "**Key Idea:** Instead of one model using all 150 features, train 150 separate models - one per feature!\n",
    "\n",
    "**How it works:**\n",
    "1. Train 150 individual Isolation Forests (one for each R-R interval feature)\n",
    "2. Each model gives an anomaly score\n",
    "3. Average all 150 scores\n",
    "4. Higher average score = more likely anomaly\n",
    "\n",
    "\n",
    "**Expected from R:** Sensitivity 92.52%, Specificity 31.45%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e42430c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 150 individual isolation forest models.\n",
      " Processed 30 / 150 features.\n",
      " Processed 60 / 150 features.\n",
      " Processed 90 / 150 features.\n",
      " Processed 120 / 150 features.\n",
      " Processed 150 / 150 features.\n",
      "Training completed in 15.59 seconds.\n",
      "Total trees: 3000 = 3000\n"
     ]
    }
   ],
   "source": [
    "# Train 150 models - One per feature \n",
    "\n",
    "n_features = X_train_scaled.shape[1] \n",
    "single_models = []\n",
    "feature_scores = np.zeros((X_test_scaled.shape[0], n_features))\n",
    "\n",
    "print(f\"Training {n_features} individual isolation forest models.\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(n_features):\n",
    "    if(i + 1) % 30 == 0:      # Progress update every 30 models\n",
    "        print(f\" Processed {i+1} / {n_features} features.\")\n",
    "    \n",
    "    # Training IF on single feature\n",
    "    single_if = IsolationForest(\n",
    "        n_estimators = 20,           # 20 Trees per model\n",
    "        max_samples = 500,\n",
    "        contamination = contamination_rate,\n",
    "        random_state = random_seed\n",
    "    )\n",
    "\n",
    "    # Fit on a single feature\n",
    "    X_train_single = X_train_scaled[:, i].reshape(-1,1)\n",
    "    single_if.fit(X_train_single)\n",
    "\n",
    "    # Predict on test set for this feature\n",
    "    X_test_single = X_test_scaled[:, i].reshape(-1,1)\n",
    "    predictions = single_if.predict(X_test_single)\n",
    "\n",
    "    # Convert to 0/1 and store\n",
    "    feature_scores[:, i] = np.where(predictions == -1, 1, 0)\n",
    "    single_models.append(single_if)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training completed in {training_time:.2f} seconds.\")\n",
    "print(f\"Total trees: {n_features * 20} = {n_features * 20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afeb0ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores for test samples: 44,394\n",
      "\n",
      "Final Predictions:\n",
      "  Normal (0):   39,645\n",
      "  Abnormal (1): 4,749\n"
     ]
    }
   ],
   "source": [
    "# Average the pridictions across all 150 features \n",
    "# Eech raw = one test sample\n",
    "# Each column = one feature's vote (0 or 1)\n",
    "# Average = What % of features say 'abnormal'\"ECG R TO PY.ipynb\"\n",
    "\n",
    "average_scores = feature_scores.mean(axis=1)\n",
    "\n",
    "print(f\"Average scores for test samples: {len(average_scores):,}\")\n",
    "\n",
    "# Determine threshold based on contamination\n",
    "# If contamination = 0.101, we want top 10.1% to be labled abnormal \n",
    "\n",
    "threshold = np.quantile(average_scores, 1 - contamination_rate)\n",
    "\n",
    "# Final prediction\n",
    "y_pred_single_var = np.where(average_scores >= threshold, 1, 0)\n",
    "\n",
    "# Count predictions\n",
    "pred_normal = sum(y_pred_single_var == 0)\n",
    "pred_abnormal = sum (y_pred_single_var == 1)\n",
    "\n",
    "print(f\"\\nFinal Predictions:\")\n",
    "print(f\"  Normal (0):   {pred_normal:,}\")\n",
    "print(f\"  Abnormal (1): {pred_abnormal:,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99fdb16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Normal     36241    3404\n",
      "       Abnormal    3420    1329\n",
      "Accuracy:    84.63%\n",
      "Sensitivity: 27.98%  (catches 28.0% of abnormal)\n",
      "Specificity: 91.41%  (catches 91.4% of normal)\n",
      "R (from paper):\n",
      "  Single-Variable IF:  Acc=85.70%, Sens=92.52%, Spec=31.45%\n",
      "\n",
      "Python (current):\n",
      "  Random Forest:       Acc=98.14%, Sens=84.62%, Spec=99.75%\n",
      "  Standard IF:         Acc=86.54%, Sens=36.57%, Spec=92.51%\n",
      "  Single-Variable IF:  Acc=84.63%, Sens=27.98%, Spec=91.41%\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics \n",
    "accuracy_sv = accuracy_score(y_test, y_pred_single_var)\n",
    "\n",
    "# confusion matrix \n",
    "cm_sv = confusion_matrix(y_test, y_pred_single_var)\n",
    "tn_sv, fn_sv, fp_sv, tp_sv = cm_sv.ravel()\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "sensitivity_sv = tp_sv / (tp_sv + fn_sv)\n",
    "specificity_sv = tn_sv / (tn_sv + fp_sv)\n",
    "\n",
    "print(f\"Actual Normal    {tn_sv:6d}  {fp_sv:6d}\")\n",
    "print(f\"       Abnormal  {fn_sv:6d}  {tp_sv:6d}\")\n",
    "\n",
    "print(f\"Accuracy:    {accuracy_sv*100:.2f}%\")\n",
    "print(f\"Sensitivity: {sensitivity_sv*100:.2f}%  (catches {sensitivity_sv*100:.1f}% of abnormal)\")\n",
    "print(f\"Specificity: {specificity_sv*100:.2f}%  (catches {specificity_sv*100:.1f}% of normal)\")\n",
    "\n",
    "print(f\"R (from paper):\")\n",
    "print(f\"  Single-Variable IF:  Acc=85.70%, Sens=92.52%, Spec=31.45%\")\n",
    "print(f\"\\nPython (current):\")\n",
    "print(f\"  Random Forest:       Acc=98.14%, Sens=84.62%, Spec=99.75%\")\n",
    "print(f\"  Standard IF:         Acc=86.54%, Sens=36.57%, Spec=92.51%\")\n",
    "print(f\"  Single-Variable IF:  Acc={accuracy_sv*100:.2f}%, Sens={sensitivity_sv*100:.2f}%, Spec={specificity_sv*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
