{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba952c4",
   "metadata": {},
   "source": [
    "# Step 3: Random Forest Implementation\n",
    "\n",
    "**Learning Objectives:**\n",
    "1. Load preprocessed data\n",
    "2. Understand Random Forest algorithm\n",
    "3. Train Random Forest classifier\n",
    "4. Make predictions on test set\n",
    "5. Evaluate performance (accuracy, sensitivity, specificity)\n",
    "6. Compare with your R implementation results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af04fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Preprocessed data loaded successfully!\n",
      "\n",
      "Training samples: 44,394\n",
      "Test samples: 44,394\n",
      "Features: 150\n",
      "Contamination rate: 0.1066\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Set seed\n",
    "random_seed = 123\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# load Preprocessed data from Step 2\n",
    "with open('preprocessed_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Extract what we need\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "contamination_rate = data['contamination_rate']\n",
    "\n",
    "print(\"✓ Preprocessed data loaded successfully!\")\n",
    "print(f\"\\nTraining samples: {X_train.shape[0]:,}\")\n",
    "print(f\"Test samples: {X_test.shape[0]:,}\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(f\"Contamination rate: {contamination_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d059b07",
   "metadata": {},
   "source": [
    "## Random Forest Algorithm\n",
    "\n",
    "**What is it?**\n",
    "- Ensemble of many decision trees (we'll use 500 trees)\n",
    "- Each tree votes on the classification\n",
    "- Final prediction = majority vote\n",
    "\n",
    "**Key parameters:**\n",
    "- `n_estimators`: Number of trees (500)\n",
    "- `max_features`: Features per split (√150 ≈ 12)\n",
    "- `random_state`: For reproducibility (123)\n",
    "\n",
    "**Why Random Forest?**\n",
    "- Baseline supervised learning method\n",
    "- High specificity (good at reducing false alarms)\n",
    "- Used in R implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d22bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Training Random Forest with 500 trees....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   27.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing the model completed in 33.16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   33.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Training Random Forest Model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import time \n",
    "\n",
    "print(\"Training Random Forest model...\")\n",
    "\n",
    "# Create the model\n",
    "# Parameters match the R model\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators  = 500,     # 500 trees\n",
    "    max_features = 'sqrt',    # Squar-root of 150 ~ 12 features per split \n",
    "    random_state = random_seed,\n",
    "    n_jobs = -1,             # USE all CPU cores\n",
    "    verbose = 1              # Show progress    \n",
    ")\n",
    "\n",
    "# Train the model \n",
    "print(\"Training Random Forest with 500 trees....\")\n",
    "start_time = time.time()\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Traing the model completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93934b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 40,291\n",
      "Abnormal: 4,103\n"
     ]
    }
   ],
   "source": [
    "# Making predictions \n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate prediction\n",
    "pred_counts = pd.Series(y_pred_rf).value_counts().sort_index()\n",
    "\n",
    "print(f\"Normal: {pred_counts[0]:,}\")\n",
    "print(f\"Abnormal: {pred_counts[1]:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "983acf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "Actual Normal       39563     98\n",
      "       Abnormal       728   4005\n",
      "Sensitivity: 84.62%  (catches 84.6% of abnormal)\n",
      "Specificity: 99.75%  (catches 99.8% of normal)\n",
      "R results: Accuracy=84.22%, Sensitivity=87.91%, Specificity=54.83%\n",
      "Python results: Accuracy=98.14%, Sensitivity=84.62%, Specificity=99.75%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix as cm_func\n",
    "cm = cm_func(y_test, y_pred_rf)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Sensitivity and specificity\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(f\"Actual Normal      {tn:6d} {fp:6d}\")\n",
    "print(f\"       Abnormal    {fn:6d} {tp:6d}\")\n",
    "\n",
    "print(f\"Sensitivity: {sensitivity*100:.2f}%  (catches {sensitivity*100:.1f}% of abnormal)\")\n",
    "print(f\"Specificity: {specificity*100:.2f}%  (catches {specificity*100:.1f}% of normal)\")\n",
    "\n",
    "print(\"R results: Accuracy=84.22%, Sensitivity=87.91%, Specificity=54.83%\")\n",
    "print(f\"Python results: Accuracy={accuracy*100:.2f}%, Sensitivity={sensitivity*100:.2f}%, Specificity={specificity*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789289f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
